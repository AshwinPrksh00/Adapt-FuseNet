# Adapt-FuseNet: Context-aware Multimodal Adaptive Fusion of Face and Gait Features using Attention Techniques for Human Identification
<img src="https://github.com/AshwinPrksh00/Adapt-FuseNet/assets/52783742/8303d871-32e3-42be-aef4-65cc28d4c416" alt="Best_Student_Paper_Badge" width="30%" height="20%">
<br><br>

Repository for the implementation of the paper "Adapt-FuseNet: Context-aware Multimodal Fusion of Face and Gait Features using Attention Techniques for Human Identification" presented in IJCB 2023.
<br><br>The paper proposes a new fusion architecture which in combination with attention techniques improves Human Identification by obtaining face and gait of the subject.<br><br>Paper Link: Coming Soon

## Environment
The code is written in Python 3.10. 
### Installation
- Download and Install Anaconda for virtual environment creation.<br>
- Clone the repository

- All the necessary packages used in the study has been included in ```requirements.txt``` file and can be installed by running<br> ```pip install -r requirements.txt``` in the repository folder

## Dataset
The study employed the use of both CASIA-A and CASIA-B dataset for training the model.<br> Data Folder structure and local machine set up will be revealed in the future.

## What's New?
- Our paper won the IAPR Best Biometrics Student Paper Award 2023 in IJCB 2023
## Citation
Coming Soon

## Pre-print
For those who are looking for the necessary methods implemented in the paper may read the preprint version on arXiv:<br>
<a href="https://arxiv.org/abs/2303.13814">Multimodal Adaptive Fusion of Face and Gait Features using Keyless attention based Deep Neural Networks for Human Identification</a> <br>- Ashwin Prakash, Thejaswin S, Athira Nambiar, Alexandre Bernardino
